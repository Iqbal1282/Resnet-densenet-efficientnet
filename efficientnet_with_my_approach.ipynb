{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from efficientnet import Efficientnet as Backbone \n",
    "from dataset import ImageDataset_iq as ImageDataset  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader \n",
    "from tensorboardX import SummaryWriter\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import logging\n",
    "import time \n",
    "import numpy as np \n",
    "from sklearn import metrics\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b0\n"
     ]
    }
   ],
   "source": [
    "model = Backbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficientnet(\n",
      "  (model): EfficientNet(\n",
      "    (_conv_stem): Conv2dStaticSamePadding(\n",
      "      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_blocks): ModuleList(\n",
      "      (0): MBConvBlock(\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (1): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (2): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (3): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (4): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (5): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (6): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (7): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (8): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (9): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (10): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (11): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (12): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (13): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (14): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "      (15): MBConvBlock(\n",
      "        (_expand_conv): Conv2dStaticSamePadding(\n",
      "          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
      "          (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        )\n",
      "        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_se_reduce): Conv2dStaticSamePadding(\n",
      "          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_se_expand): Conv2dStaticSamePadding(\n",
      "          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_project_conv): Conv2dStaticSamePadding(\n",
      "          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (static_padding): Identity()\n",
      "        )\n",
      "        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "        (_swish): MemoryEfficientSwish()\n",
      "      )\n",
      "    )\n",
      "    (_conv_head): Conv2dStaticSamePadding(\n",
      "      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
      "    (_dropout): Dropout(p=0.2, inplace=False)\n",
      "    (_fc): Linear(in_features=1280, out_features=5, bias=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = 'data_segmented/'\n",
    "\n",
    "TRAIN_CSV = DATA_FOLDER +'CheXpert-v1.0-small/train_frontal.csv'\n",
    "VALID_CSV = DATA_FOLDER + 'CheXpert-v1.0-small/dev_frontal.csv'\n",
    "IMAGE_SHAPE = 256 \n",
    "TRAIN_BATCH_SIZE = 24\n",
    "VALID_BATCH_SIZE = 24\n",
    "EPOCHS = 10 \n",
    "lr = 0.0001\n",
    "log_every = 10\n",
    "test_every = 100 \n",
    "run = 'logdir2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(ImageDataset(TRAIN_CSV, IMAGE_SHAPE, subfolder = DATA_FOLDER), batch_size = TRAIN_BATCH_SIZE,shuffle = True, drop_last = True)\n",
    "dataloader_dev = DataLoader(ImageDataset(VALID_CSV, IMAGE_SHAPE, subfolder = DATA_FOLDER), batch_size = VALID_BATCH_SIZE,shuffle = True, drop_last = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_header = dataloader_dev.dataset._label_header\n",
    "\n",
    "summary = {'epoch': 0, 'step': 0}\n",
    "summary_dev = {'loss': float('inf'), 'acc': 0.0}\n",
    "summary_writer = SummaryWriter(run)\n",
    "epoch_start = 0\n",
    "best_dict = {\n",
    "    \"acc_dev_best\": 0.0,\n",
    "    \"auc_dev_best\": 0.0,\n",
    "    \"loss_dev_best\": float('inf'),\n",
    "    \"fused_dev_best\": 0.0,\n",
    "    \"best_idx\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(output, target, index, device):\n",
    "    num_classes = [1,1,1,1,1]\n",
    "    batch_weight = False \n",
    "    criterion = 'BCE'\n",
    "    if criterion == 'BCE':\n",
    "        for num_class in num_classes:\n",
    "            assert num_class == 1\n",
    "        target = target[:, index].view(-1)\n",
    "        pos_weight = torch.from_numpy(\n",
    "            np.array([1,1,1,1,1],\n",
    "                     dtype=np.float32)).to(device).type_as(target)\n",
    "        if batch_weight:\n",
    "            if target.sum() == 0:\n",
    "                loss = torch.tensor(0., requires_grad=True).to(device)\n",
    "            else:\n",
    "                weight = (target.size()[0] - target.sum()) / target.sum()\n",
    "                loss = F.binary_cross_entropy_with_logits(\n",
    "                    output[index].view(-1), target, pos_weight=weight)\n",
    "        else:\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(\n",
    "                output[:,index].view(-1), target, pos_weight=pos_weight[index])\n",
    "\n",
    "        label = torch.sigmoid(output[:,index].view(-1)).ge(0.5).float()\n",
    "        acc = (target == label).float().sum() / len(label)\n",
    "    else:\n",
    "        raise Exception('Unknown criterion : {}'.format(criterion))\n",
    "\n",
    "    return (loss, acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(summary, run, device,  model, dataloader):\n",
    "    torch.set_grad_enabled(False)\n",
    "    model.eval()\n",
    "    num_classes = 5 \n",
    "    num_tasks = 5 \n",
    "    steps = len(dataloader)\n",
    "    dataiter = iter(dataloader)\n",
    "    #num_tasks = len(num_classes)\n",
    "\n",
    "    loss_sum = np.zeros(num_tasks)\n",
    "    acc_sum = np.zeros(num_tasks)\n",
    "\n",
    "    predlist = list(x for x in range(num_classes))\n",
    "    true_list = list(x for x in range(num_classes))\n",
    "    for step in range(steps):\n",
    "        image, target = next(dataiter)\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(image)\n",
    "        # different number of tasks\n",
    "        for t in range(num_classes):\n",
    "\n",
    "            loss_t, acc_t = get_loss(output, target, t, device)\n",
    "            # AUC\n",
    "            output_tensor = torch.sigmoid(\n",
    "                output[:,t].view(-1)).cpu().detach().numpy()\n",
    "            target_tensor = target[:, t].view(-1).cpu().detach().numpy()\n",
    "            if step == 0:\n",
    "                predlist[t] = output_tensor\n",
    "                true_list[t] = target_tensor\n",
    "            else:\n",
    "                predlist[t] = np.append(predlist[t], output_tensor)\n",
    "                true_list[t] = np.append(true_list[t], target_tensor)\n",
    "\n",
    "            loss_sum[t] += loss_t.item()\n",
    "            acc_sum[t] += acc_t.item()\n",
    "    summary['loss'] = loss_sum / steps\n",
    "    summary['acc'] = acc_sum / steps\n",
    "\n",
    "    return summary, predlist, true_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(summary, summary_dev, run, model, dataloader, dataloader_dev, optimizer,device):\n",
    "    torch.set_grad_enabled(True)\n",
    "    model.train()\n",
    "    steps = len(dataloader)\n",
    "    dataiter = iter(dataloader)\n",
    "    label_header = dataloader.dataset._label_header\n",
    "    num_tasks =5\n",
    "    num_classes = 5 \n",
    "    \n",
    "    time_now = time.time()\n",
    "    loss_sum = np.zeros(num_tasks)\n",
    "    acc_sum = np.zeros(num_tasks)\n",
    "    \n",
    "    for step in tqdm.tqdm(range(steps)):\n",
    "        image, target = next(dataiter)\n",
    "        #print(image.shape)\n",
    "        #print(target.shape)\n",
    "        #raise Exception\n",
    "        image = image.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        output = model(image)\n",
    "        \n",
    "        # different number of tasks\n",
    "        loss = 0\n",
    "        for t in range(num_tasks):\n",
    "            loss_t, acc_t = get_loss(output, target, t, device)\n",
    "            loss += loss_t\n",
    "            loss_sum[t] += loss_t.item()\n",
    "            acc_sum[t] += acc_t.item()\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        summary['step'] += 1\n",
    "        \n",
    "        if summary['step'] % log_every == 0:\n",
    "            time_spent = time.time() - time_now\n",
    "            time_now = time.time()\n",
    "\n",
    "            loss_sum /= log_every\n",
    "            acc_sum /= log_every\n",
    "            loss_str = ' '.join(map(lambda x: '{:.5f}'.format(x), loss_sum))\n",
    "            acc_str = ' '.join(map(lambda x: '{:.3f}'.format(x), acc_sum))\n",
    "\n",
    "            logging.info(\n",
    "                '{}, Train, Epoch : {}, Step : {}, Loss : {}, '\n",
    "                'Acc : {}, Run Time : {:.2f} sec'\n",
    "                .format(time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        summary['epoch'] + 1, summary['step'], loss_str,\n",
    "                        acc_str, time_spent))\n",
    "            \n",
    "            for t in range(num_tasks):\n",
    "                summary_writer.add_scalar(\n",
    "                    'train/loss_{}'.format(label_header[t]), loss_sum[t],\n",
    "                    summary['step'])\n",
    "                summary_writer.add_scalar(\n",
    "                    'train/acc_{}'.format(label_header[t]), acc_sum[t],\n",
    "                    summary['step'])\n",
    "\n",
    "                \n",
    "            loss_sum = np.zeros(num_tasks)\n",
    "            acc_sum = np.zeros(num_tasks)\n",
    "            \n",
    "            \n",
    "        if summary['step'] % test_every == 0:\n",
    "            time_now = time.time()\n",
    "            summary_dev, predlist, true_list = test_epoch(\n",
    "                summary_dev,run, device,  model, dataloader_dev)\n",
    "            time_spent = time.time() - time_now\n",
    "\n",
    "            auclist = []\n",
    "            for i in range(num_classes):\n",
    "                y_pred = predlist[i]\n",
    "                y_true = true_list[i]\n",
    "                fpr, tpr, thresholds = metrics.roc_curve(\n",
    "                    y_true, y_pred, pos_label=1)\n",
    "                auc = metrics.auc(fpr, tpr)\n",
    "                auclist.append(auc)\n",
    "            summary_dev['auc'] = np.array(auclist)\n",
    "\n",
    "            loss_dev_str = ' '.join(map(lambda x: '{:.5f}'.format(x),\n",
    "                                        summary_dev['loss']))\n",
    "            acc_dev_str = ' '.join(map(lambda x: '{:.3f}'.format(x),\n",
    "                                       summary_dev['acc']))\n",
    "            auc_dev_str = ' '.join(map(lambda x: '{:.3f}'.format(x),\n",
    "                                       summary_dev['auc']))\n",
    "\n",
    "            logging.info(\n",
    "                '{}, Dev, Step : {}, Loss : {}, Acc : {}, Auc : {},'\n",
    "                'Mean auc: {:.3f} ''Run Time : {:.2f} sec' .format(\n",
    "                    time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                    summary['step'],\n",
    "                    loss_dev_str,\n",
    "                    acc_dev_str,\n",
    "                    auc_dev_str,\n",
    "                    summary_dev['auc'].mean(),\n",
    "                    time_spent))\n",
    "\n",
    "            for t in range(num_classes):\n",
    "                summary_writer.add_scalar(\n",
    "                    'dev/loss_{}'.format(dev_header[t]),\n",
    "                    summary_dev['loss'][t], summary['step'])\n",
    "                summary_writer.add_scalar(\n",
    "                    'dev/acc_{}'.format(dev_header[t]), summary_dev['acc'][t],\n",
    "                    summary['step'])\n",
    "                summary_writer.add_scalar(\n",
    "                    'dev/auc_{}'.format(dev_header[t]), summary_dev['auc'][t],\n",
    "                    summary['step'])\n",
    "                \n",
    "                \n",
    "            save_index = [0,1,2,3,4]\n",
    "            best_target ='auc'\n",
    "            save_best = False\n",
    "            mean_acc = summary_dev['acc'][save_index].mean()\n",
    "            if mean_acc >= best_dict['acc_dev_best']:\n",
    "                best_dict['acc_dev_best'] = mean_acc\n",
    "                if best_target == 'acc':\n",
    "                    save_best = True\n",
    "\n",
    "            mean_auc = summary_dev['auc'][save_index].mean()\n",
    "            if mean_auc >= best_dict['auc_dev_best']:\n",
    "                best_dict['auc_dev_best'] = mean_auc\n",
    "                if best_target == 'auc':\n",
    "                    save_best = True\n",
    "\n",
    "            mean_loss = summary_dev['loss'][save_index].mean()\n",
    "            if mean_loss <= best_dict['loss_dev_best']:\n",
    "                best_dict['loss_dev_best'] = mean_loss\n",
    "                if best_target == 'loss':\n",
    "                    save_best = True\n",
    "\n",
    "            if save_best:\n",
    "                torch.save(\n",
    "                    {'epoch': summary['epoch'],\n",
    "                     'step': summary['step'],\n",
    "                     'acc_dev_best': best_dict['acc_dev_best'],\n",
    "                     'auc_dev_best': best_dict['auc_dev_best'],\n",
    "                     'loss_dev_best': best_dict['loss_dev_best'],\n",
    "                     'state_dict': model.state_dict()},\n",
    "                    os.path.join(run, 'best{}.ckpt'.format(\n",
    "                        best_dict['best_idx']))\n",
    "                )\n",
    "                best_dict['best_idx'] += 1\n",
    "                if best_dict['best_idx']>3:\n",
    "                    best_dict['best_idx'] = 1\n",
    "                logging.info(\n",
    "                    '{}, Best, Step : {}, Loss : {}, Acc : {},Auc :{},'\n",
    "                    'Best Auc : {:.3f}' .format(\n",
    "                        time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "                        summary['step'],\n",
    "                        loss_dev_str,\n",
    "                        acc_dev_str,\n",
    "                        auc_dev_str,\n",
    "                        best_dict['auc_dev_best']))\n",
    "        model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "    summary['epoch'] += 1\n",
    "\n",
    "    return summary, best_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                            | 53/7959 [08:12<20:24:25,  9.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-b9724b159ce2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummary_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_dev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-26bf3db0c433>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(summary, summary_dev, run, model, dataloader, dataloader_dev, optimizer, device)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\md. iqbal hossain\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\torch\\autograd\\function.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0m_is_legacy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m# _forward_cls is defined by derived class\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    train_epoch(summary, summary_dev, run, model, dataloader_train, dataloader_dev, optimizer,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
